[2025-04-23 19:39:53,571] [INFO] Loading Faster-Whisper model...
[2025-04-23 19:39:54,874] [INFO] Model loaded.
[2025-04-23 19:40:40,951] [INFO] Loading Faster-Whisper model...
[2025-04-23 19:40:41,327] [INFO] Model loaded.
[2025-04-23 19:41:42,947] [INFO] Loading Faster-Whisper model...
[2025-04-23 19:41:43,377] [INFO] Model loaded.
[2025-04-23 19:56:42,105] [INFO] Loading Faster-Whisper model...
[2025-04-23 19:56:42,701] [INFO] Model loaded.
[2025-04-23 20:19:00,643] [INFO] Received transcription request
[2025-04-23 20:19:01,109] [INFO] Processing audio with duration 00:02.613
[2025-04-23 20:19:03,229] [INFO] Transcription successful: 
[2025-04-23 20:21:51,266] [INFO] Loading Faster-Whisper model...
[2025-04-23 20:21:51,969] [INFO] Model loaded.
[2025-04-23 21:53:16,807] [INFO] Loading Faster-Whisper model...
[2025-04-23 21:53:17,444] [INFO] Model loaded.
[2025-04-23 21:53:20,374] [INFO] Received transcription request
[2025-04-23 21:53:20,442] [INFO] Processing audio with duration 00:06.912
[2025-04-23 21:53:20,792] [INFO] Transcription successful:  Não tive filhos, não transmitia nenhuma criatura, o legado de nossa miseria.  Machado de assiste.
[2025-04-23 21:53:47,206] [INFO] Received transcription request
[2025-04-23 21:53:47,275] [INFO] Processing audio with duration 00:06.912
[2025-04-23 21:53:47,392] [INFO] Transcription successful:  Não tive filhos, não transmitia nenhuma criatura, o legado de nossa miseria.  Machado de assiste.
[2025-04-23 21:54:38,116] [INFO] Loading Faster-Whisper model...
[2025-04-23 21:54:38,725] [INFO] Model loaded.
[2025-04-23 21:54:54,037] [INFO] Received transcription request
[2025-04-23 21:54:54,137] [INFO] Processing audio with duration 00:02.613
[2025-04-23 21:54:54,776] [INFO] Transcription successful: 
[2025-04-23 22:26:54,530] [INFO] Received transcription request
[2025-04-23 22:26:54,616] [INFO] Processing audio with duration 00:04.080
[2025-04-23 22:26:54,701] [INFO] Transcription successful:  1, 2, 3, isto é um teste.
[2025-04-24 19:30:56,043] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:30:56,963] [INFO] Model loaded.
[2025-04-24 19:40:47,143] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:40:47,799] [INFO] Model loaded.
[2025-04-24 19:42:18,310] [INFO] Received transcription request
[2025-04-24 19:42:18,397] [INFO] Processing audio with duration 00:04.080
[2025-04-24 19:42:18,958] [INFO] Transcription successful:  1, 2, 3, isto é um teste.
[2025-04-24 19:45:00,123] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:45:00,853] [INFO] Model loaded.
[2025-04-24 19:46:29,678] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:46:30,206] [INFO] Model loaded.
[2025-04-24 19:46:58,144] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:46:58,665] [INFO] Model loaded.
[2025-04-24 19:48:42,351] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:48:43,152] [INFO] Model loaded.
[2025-04-24 19:48:58,685] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:48:59,137] [INFO] Model loaded.
[2025-04-24 19:54:24,413] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:54:24,875] [INFO] Model loaded.
[2025-04-24 19:54:56,913] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:54:57,412] [INFO] Model loaded.
[2025-04-24 19:55:01,750] [INFO] Received transcription request
[2025-04-24 19:55:01,822] [INFO] Processing audio with duration 00:04.080
[2025-04-24 19:55:02,150] [INFO] Transcription successful:  1, 2, 3, isto é um teste.
[2025-04-24 19:57:25,360] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:57:26,194] [INFO] Model loaded.
[2025-04-24 19:58:13,881] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:58:14,383] [INFO] Model loaded.
[2025-04-24 19:58:25,774] [INFO] Loading Faster-Whisper model...
[2025-04-24 19:58:26,487] [INFO] Model loaded.
[2025-04-24 19:59:54,918] [INFO] Received transcription request
[2025-04-24 19:59:55,008] [INFO] Processing audio with duration 00:03.300
[2025-04-24 19:59:55,354] [INFO] Transcription successful:  1, 2, 3, gravando um áudio.
[2025-04-24 20:02:33,034] [INFO] Received transcription request
[2025-04-24 20:02:33,035] [ERROR] Transcription failed
Traceback (most recent call last):
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 59, in transcribe_audio
    audio_bytes = base64.b64decode(request.audio_base64)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/.pyenv/versions/3.11.10/lib/python3.11/base64.py", line 88, in b64decode
    return binascii.a2b_base64(s, strict_mode=validate)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
binascii.Error: Incorrect padding
[2025-04-24 20:03:32,008] [INFO] Received transcription request
[2025-04-24 20:03:32,134] [INFO] Processing audio with duration 00:03.480
[2025-04-24 20:03:32,259] [INFO] Transcription successful:  Olá, isto é um áudio testando com 2-3.
[2025-04-24 20:16:22,192] [INFO] Received transcription request
[2025-04-24 20:16:22,345] [INFO] Processing audio with duration 00:03.540
[2025-04-24 20:16:22,448] [INFO] Transcription successful:  Olá, o código vai funcionar.
[2025-04-24 20:21:00,572] [INFO] Received transcription request
[2025-04-24 20:21:00,713] [INFO] Processing audio with duration 00:03.540
[2025-04-24 20:21:00,806] [INFO] Transcription successful:  Renato, você é legal.
[2025-04-24 20:21:53,526] [INFO] Received transcription request
[2025-04-24 20:21:53,644] [INFO] Processing audio with duration 00:03.240
[2025-04-24 20:21:53,743] [INFO] Transcription successful:  O botão resetar não está funcionando.
[2025-04-24 20:25:51,592] [INFO] Received transcription request
[2025-04-24 20:25:51,692] [INFO] Processing audio with duration 00:06.060
[2025-04-24 20:25:51,817] [INFO] Transcription successful:  E este é uma fala, falar de normalmente, com bastante reflexão na verdade na fala.
[2025-04-24 21:48:59,435] [INFO] Loading Faster-Whisper model...
[2025-04-24 21:49:00,035] [INFO] Model loaded.
[2025-04-24 21:49:37,687] [INFO] Received transcription request
[2025-04-24 21:49:37,802] [INFO] Processing audio with duration 00:06.480
[2025-04-24 21:49:38,193] [INFO] Transcription successful:  Portanto, logo depois de resolver este problema, não se esqueça de criar um comite.
[2025-04-25 13:06:10,519] [INFO] Loading Faster-Whisper model...
[2025-04-25 13:08:42,943] [INFO] Loading Faster-Whisper model...
[2025-04-25 13:08:45,013] [INFO] Model loaded.
[2025-04-25 13:09:32,627] [INFO] Received transcription request
[2025-04-25 13:09:32,722] [INFO] Processing audio with duration 00:02.760
[2025-04-25 13:09:33,327] [INFO] Transcription successful:  1, 2, 3 testando
[2025-04-25 15:48:29,817] [INFO] Received transcription request
[2025-04-25 15:48:29,948] [INFO] Processing audio with duration 00:03.120
[2025-04-25 15:50:45,553] [INFO] Loading Faster-Whisper model...
[2025-04-25 15:50:48,112] [INFO] Model loaded.
[2025-04-25 15:51:27,414] [INFO] Received transcription request
[2025-04-25 15:51:27,571] [INFO] Processing audio with duration 00:03.060
[2025-04-25 15:51:30,831] [INFO] Transcription successful:  O Hato junho a roupa do Rei de rua.
[2025-04-25 16:09:14,928] [INFO] Loading Faster-Whisper model...
[2025-04-25 16:09:20,186] [INFO] Model loaded.
[2025-04-25 16:10:12,839] [INFO] Received transcription request
[2025-04-25 16:10:12,920] [INFO] Processing audio with duration 00:03.480
[2025-04-25 16:10:13,951] [INFO] Transcription successful:  O rato roeu a roupa do rei de Roma.
[2025-04-25 16:26:42,088] [INFO] Loading Faster-Whisper model...
[2025-04-25 16:28:29,756] [INFO] Loading Faster-Whisper model...
[2025-04-25 16:28:37,260] [INFO] Model loaded.
[2025-04-25 16:28:56,085] [INFO] Received transcription request
[2025-04-25 16:28:56,252] [INFO] Processing audio with duration 00:04.020
[2025-04-25 16:29:03,646] [INFO] Transcription successful:  O rato roeu a roupa do rei de roubo.
[2025-04-25 16:30:02,542] [INFO] Received transcription request
[2025-04-25 16:30:02,697] [INFO] Processing audio with duration 00:04.320
[2025-04-25 16:30:08,482] [INFO] Transcription successful:  O rato reiu a roupa do rei de Roma.
[2025-05-07 13:48:04,143] [INFO] Loading Faster-Whisper model...
[2025-05-07 13:48:05,753] [INFO] Model loaded.
[2025-05-07 13:48:29,458] [INFO] Received transcription request
[2025-05-07 13:48:29,561] [INFO] Processing audio with duration 00:03.600
[2025-05-07 13:48:30,463] [INFO] Transcription successful:  Obrigado por assistir.
[2025-05-07 13:59:47,687] [INFO] Received transcription request
[2025-05-07 13:59:47,784] [INFO] Processing audio with duration 00:02.880
[2025-05-07 13:59:47,847] [ERROR] Transcription failed
Traceback (most recent call last):
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in transcribe_audio
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in <listcomp>
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1148, in generate_segments
    encoder_output = self.encode(segment)
                     ^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1358, in encode
    return self.model.encode(features, to_cpu=to_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA failed with error out of memory
[2025-05-07 14:00:10,555] [INFO] Received transcription request
[2025-05-07 14:00:10,640] [INFO] Processing audio with duration 00:02.700
[2025-05-07 14:00:10,659] [ERROR] Transcription failed
Traceback (most recent call last):
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in transcribe_audio
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in <listcomp>
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1148, in generate_segments
    encoder_output = self.encode(segment)
                     ^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1358, in encode
    return self.model.encode(features, to_cpu=to_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA failed with error out of memory
[2025-05-07 14:00:29,962] [INFO] Received transcription request
[2025-05-07 14:00:30,024] [INFO] Processing audio with duration 00:01.980
[2025-05-07 14:00:30,052] [ERROR] Transcription failed
Traceback (most recent call last):
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in transcribe_audio
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in <listcomp>
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1148, in generate_segments
    encoder_output = self.encode(segment)
                     ^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1358, in encode
    return self.model.encode(features, to_cpu=to_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA failed with error out of memory
[2025-05-07 14:01:30,423] [INFO] Received transcription request
[2025-05-07 14:01:30,488] [INFO] Processing audio with duration 00:02.400
[2025-05-07 14:01:30,529] [ERROR] Transcription failed
Traceback (most recent call last):
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in transcribe_audio
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/Documents/Mestrado/PLN/PLN-SCC5908/asr-api/asr_api/app.py", line 64, in <listcomp>
    transcription = " ".join([segment.text for segment in segments])
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1148, in generate_segments
    encoder_output = self.encode(segment)
                     ^^^^^^^^^^^^^^^^^^^^
  File "/home/antonio/venvs/pln-asr-py31110/lib/python3.11/site-packages/faster_whisper/transcribe.py", line 1358, in encode
    return self.model.encode(features, to_cpu=to_cpu)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: CUDA failed with error out of memory
[2025-05-07 14:04:13,396] [INFO] Loading Faster-Whisper model...
[2025-05-07 14:04:14,755] [INFO] Model loaded.
[2025-05-07 14:04:33,709] [INFO] Received transcription request
[2025-05-07 14:04:33,798] [INFO] Processing audio with duration 00:02.280
[2025-05-07 14:04:34,615] [INFO] Transcription successful:  Um, dois, três.
[2025-05-07 14:04:51,522] [INFO] Loading Faster-Whisper model...
[2025-05-07 14:04:52,663] [INFO] Model loaded.
